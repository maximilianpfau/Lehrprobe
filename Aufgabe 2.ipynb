{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aufgabe 2: \" Convolutional Neural Network (CNN)\" für Bilddaten\n",
    "\n",
    "### CNN Seminar des Biomedical Data Science Curriculums\n",
    "\n",
    "<span style=\"color:red\">**Anmerkung:** Version mit Lösung für die Lehrprobe, Universitätsmedizin Göttingen,\n",
    "Freitag, 25. September 2020 </span>\n",
    "\n",
    "\n",
    "**Ziel:** Training eines \" Convolutional Neural Network (CNN)\" für die Klassifikation der MNIST Zahlen\n",
    "\n",
    "**ToDo:**\n",
    "- Vervollständigen Sie die Lücken im Code (mit #ToDo und Kommentar versehenen)\n",
    "- Führen Sie am Ende die Selbstkontrolle aus, um die Funktionalität sicherzustellen\n",
    "- Reichen Sie den finalen Code per Email als *.html Export ein\n",
    "\n",
    "**Lernziele:**\n",
    "- Definition eines mehrschichtigen CNN in PyTorch (Convolution und Pooling Layers)\n",
    "\n",
    "**Vorgeschlagene Architektur des CNN**\n",
    "\n",
    "<img src=\"figures/CNN.png\" width=800px>\n",
    "\n",
    "<img src=\"figures/example_2.png\" width=300px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vorbereitung - keine Änderungen in diesem Block notwendig\n",
    "\n",
    "# Import der Bibliotheken\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Definition von \"transform\" um die Daten zu normalisieren\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,)), ])\n",
    "\n",
    "# Download der MNIST Daten\n",
    "data_set = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "\n",
    "# Daten Aufteilung und Definition des \"trainloader\"\n",
    "train_set, val_set = torch.utils.data.random_split(data_set, [50000, 10000])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_set, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teilaufgabe 1: Definiere ein einfaches NN mit 768 input features und 10 output features (für die Ziffern 0 - 9)\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        # Definiere erste 2D convolution mit 1 input channel, 16 output channels, und kernel size 3,\n",
    "        # stride von 1 und padding von 1\n",
    "        self.conv1 = # ToDo\n",
    "        \n",
    "        # Definiere  pooling Schicht (max pooling mit kernel size 2 und stride 2)\n",
    "        self.pool = # ToDo\n",
    "        \n",
    "        # Definiere zweite 2D convolution mit 1 input channel, 16 output channels, und kernel size 3\n",
    "        # stride von 1 und padding von 1\n",
    "        self.conv2 = # ToDo\n",
    "\n",
    "        # Definiere \"fully connected Schichten\" von 1568 Neuronen zu 124 Neuronen, zu 64 Neuronen,\n",
    "        # zu 10 Neuronen für die Ziffern 0 bis 9 \n",
    "        self.fc1 = # ToDo\n",
    "        self.fc2 = # ToDo\n",
    "        self.fc3 = # ToDo\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.log_softmax(self.fc3(x), dim=1)\n",
    "        return x\n",
    "\n",
    "model = CNN()\n",
    "\n",
    "\n",
    "loss_function = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.003)\n",
    "\n",
    "# Äußerer Loop für die Epochen\n",
    "epochs = 5\n",
    "for e in range(epochs):\n",
    "    \n",
    "    # Loop für Training\n",
    "    running_train_loss = 0\n",
    "    for images, labels in train_loader:\n",
    "        \n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(images)\n",
    "        train_loss = loss_function(output, labels)\n",
    "        \n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_train_loss += train_loss.item()\n",
    "        \n",
    "    print(f\"Training loss: {running_train_loss/len(train_loader)}\")\n",
    "    \n",
    "    # Loop für Validation\n",
    "    running_val_loss = 0\n",
    "    for images, labels in val_loader:\n",
    "        \n",
    "        output = model(images)\n",
    "        val_loss = loss_function(output, labels)\n",
    "        \n",
    "        running_val_loss += val_loss.item()\n",
    "        \n",
    "    print(f\"Validation loss: {running_val_loss/len(val_loader)}\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lösung\n",
    "\n",
    "<span style=\"color:red\">**Anmerkung:** Version mit Lösung für die Lehrprobe, Universitätsmedizin Göttingen,\n",
    "Freitag, 25. September 2020 </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.289614979568345\n",
      "Validation loss: 2.268726892532057\n",
      "Training loss: 2.197058551146856\n",
      "Validation loss: 2.0436026359060007\n",
      "Training loss: 1.538117558221378\n",
      "Validation loss: 0.9627786745690996\n",
      "Training loss: 0.6393970234695908\n",
      "Validation loss: 0.5171161563533127\n",
      "Training loss: 0.39316412564509967\n",
      "Validation loss: 0.3694345478419286\n"
     ]
    }
   ],
   "source": [
    "# Teilaufgabe 1: Definiere ein einfaches NN mit 768 input features und 10 output features (für die Ziffern 0 - 9)\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        # Definiere erste 2D convolution mit 1 input channel, 16 output channels, und kernel size 3\n",
    "        # stride von 1 und padding von 1\n",
    "        self.conv1 = nn.Conv2d(1, 16, 3, stride=1, padding=1)\n",
    "        \n",
    "        # Definiere  pooling Schicht (max pooling mit kernel size 2 und stride 2)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # Definiere zweite 2D convolution mit 1 input channel, 16 output channels, und kernel size 3\n",
    "        # stride von 1 und padding von 1\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, stride=1, padding=1)\n",
    "\n",
    "        # Definiere \"fully connected Schichten\" von 1568 Neuronen zu 124 Neuronen, zu 64 Neuronen,\n",
    "        # zu 10 Neuronen für die Ziffern 0 bis 9 \n",
    "        self.fc1 = nn.Linear(32 * 7 * 7, 124)\n",
    "        self.fc2 = nn.Linear(124, 64)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.log_softmax(self.fc3(x), dim=1)\n",
    "        return x\n",
    "\n",
    "model = CNN()\n",
    "\n",
    "\n",
    "loss_function = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.003)\n",
    "\n",
    "# Äußerer Loop für die Epochen\n",
    "epochs = 5\n",
    "for e in range(epochs):\n",
    "    \n",
    "    # Loop für Training\n",
    "    running_train_loss = 0\n",
    "    for images, labels in train_loader:\n",
    "        \n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(images)\n",
    "        train_loss = loss_function(output, labels)\n",
    "        \n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_train_loss += train_loss.item()\n",
    "        \n",
    "    print(f\"Training loss: {running_train_loss/len(train_loader)}\")\n",
    "    \n",
    "    # Loop für Validation\n",
    "    running_val_loss = 0\n",
    "    for images, labels in val_loader:\n",
    "        \n",
    "        output = model(images)\n",
    "        val_loss = loss_function(output, labels)\n",
    "        \n",
    "        running_val_loss += val_loss.item()\n",
    "        \n",
    "    print(f\"Validation loss: {running_val_loss/len(val_loader)}\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selbstkontrolle\n",
    "Führen Sie den folgenden Code aus, um die Funktion Ihres NN zu überprüfen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.axis.YTick at 0x2b64ee6aac8>,\n",
       " <matplotlib.axis.YTick at 0x2b64ee6a4a8>,\n",
       " <matplotlib.axis.YTick at 0x2b64efdec50>,\n",
       " <matplotlib.axis.YTick at 0x2b64eeb67f0>,\n",
       " <matplotlib.axis.YTick at 0x2b64eeb6c88>,\n",
       " <matplotlib.axis.YTick at 0x2b64eec3198>,\n",
       " <matplotlib.axis.YTick at 0x2b64eec35f8>,\n",
       " <matplotlib.axis.YTick at 0x2b64eec3a90>,\n",
       " <matplotlib.axis.YTick at 0x2b64eeb6978>,\n",
       " <matplotlib.axis.YTick at 0x2b64eec3240>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Extraktion eines Beispielbilds\n",
    "images, labels = next(iter(val_loader))\n",
    "\n",
    "# NN ausführen\n",
    "pred_logprobs = model(images)\n",
    "\n",
    "# Log-Wahrscheinlichkeit zu Standardeinheitsintervall\n",
    "pred_probs = torch.exp(pred_logprobs)\n",
    "\n",
    "# Plotten des Ergebnisses\n",
    "fig, (ax1, ax2) = plt.subplots(figsize=(6,3), ncols=2)\n",
    "\n",
    "ax1.imshow(images[0][0])\n",
    "ax2.barh(np.arange(10), pred_probs[0].data.numpy().squeeze())\n",
    "ax2.set_yticks(np.arange(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
